{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOqtixLa1y-b"
      },
      "source": [
        "The following example notebook implements standard diffusion\n",
        "with a simple CNN model to generate realistic MNIST digits.\n",
        "\n",
        "This is a modified implementation of `minDiffusion`\n",
        "which implements [DDPM](https://arxiv.org/abs/2006.11239)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlzMxqOr7yBh"
      },
      "source": [
        "To run this example notebook,\n",
        "install requirements as in `requirements.txt` (for example, `pip install -r requirements.txt`).\n",
        "You may also wish to follow system-dependent PyTorch instructions\n",
        "[here](https://pytorch.org/) to install accelerated\n",
        "versions of PyTorch, but note they are not needed\n",
        "(I am testing this on my laptop).\n",
        "\n",
        "If you do use accelerated hardware, make sure that your code\n",
        "is still compatible with CPU-only installs.\n",
        "\n",
        "First, let's create a folder to store example images:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate==0.27.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAgTDf0Y0kFL",
        "outputId": "f1a28d1d-24e4-4bb0-f118-fb7feb38f83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate==0.27.2\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/280.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/280.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/280.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m245.8/280.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.2) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.27.2)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.27.2)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.27.2)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate==0.27.2)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate==0.27.2)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate==0.27.2)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate==0.27.2)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate==0.27.2)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate==0.27.2)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate==0.27.2)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.27.2)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.2) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.27.2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.27.2) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.27.2) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.27.2) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.27.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaJ7P2ft2G6j"
      },
      "outputs": [],
      "source": [
        "!mkdir -p contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50FGtZsk1y-b"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# from accelerate import Accelerator\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import save_image, make_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVbI7kzC7yBi"
      },
      "source": [
        "The following function creates a DDPM training schedule for use when evaluating\n",
        "and training the diffusion model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMQ1-BSc1y-c"
      },
      "outputs": [],
      "source": [
        "def ddpm_schedules(alpha1: float, alpha2: float, T: int) -> Dict[str, torch.Tensor]:\n",
        "    \"\"\"Returns pre-computed schedules for DDPM sampling with a linear noise schedule.\"\"\"\n",
        "    assert alpha1 > 1.0 and alpha2 > 1.0 and alpha1 > alpha2, \"alpha1 and alpha2 must be greater than 1 and alpha1 must be greater than alpha2\"\n",
        "\n",
        "    alpha_t = alpha1 - (alpha1 - alpha2) * torch.arange(0, T + 1, dtype=torch.float32) / T\n",
        "\n",
        "    return {\"alpha_t\": alpha_t}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddpm_schedules(10, 4, T=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQzdZUiiKxK-",
        "outputId": "abbd07fd-966e-4120-cfff-07fc99326c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha_t': tensor([10.0000,  9.4000,  8.8000,  8.2000,  7.6000,  7.0000,  6.4000,  5.8000,\n",
              "          5.2000,  4.6000,  4.0000])}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_fRlryJ7yBj"
      },
      "source": [
        "Next, we create a simple 2D convolutional neural network. This network\n",
        "is essentially going to try to estimate the diffusion process --- we\n",
        "can then use this network to generate realistic images.\n",
        "\n",
        "First, we create a single CNN block which we will stack to create the\n",
        "full network. We use `LayerNorm` for stable training and no batch dependence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d16i_bcV1y-d"
      },
      "outputs": [],
      "source": [
        "class CNNBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        *,\n",
        "        expected_shape,\n",
        "        act=nn.GELU,\n",
        "        kernel_size=7,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
        "            nn.LayerNorm(expected_shape),\n",
        "            act()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuqC-ZGN7yBj"
      },
      "source": [
        "We then create the full CNN model, which is a stack of these blocks\n",
        "according to the `n_hidden` tuple, which specifies the number of\n",
        "channels at each hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSvzdt1f1y-d"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        expected_shape=(28, 28),\n",
        "        n_hidden=(64, 128, 64),\n",
        "        kernel_size=7,\n",
        "        last_kernel_size=3,\n",
        "        time_embeddings=16,\n",
        "        act=nn.GELU,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        last = in_channels\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        for hidden in n_hidden:\n",
        "            self.blocks.append(\n",
        "                CNNBlock(\n",
        "                    last,\n",
        "                    hidden,\n",
        "                    expected_shape=expected_shape,\n",
        "                    kernel_size=kernel_size,\n",
        "                    act=act,\n",
        "                )\n",
        "            )\n",
        "            last = hidden\n",
        "\n",
        "        # The final layer, we use a regular Conv2d to get the\n",
        "        # correct scale and shape (and avoid applying the activation)\n",
        "        self.blocks.append(\n",
        "            nn.Conv2d(\n",
        "                last,\n",
        "                in_channels,\n",
        "                last_kernel_size,\n",
        "                padding=last_kernel_size // 2,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        ## This part is literally just to put the single scalar \"t\" into the CNN\n",
        "        ## in a nice, high-dimensional way:\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(time_embeddings * 2, 128), act(),\n",
        "            nn.Linear(128, 128), act(),\n",
        "            nn.Linear(128, 128), act(),\n",
        "            nn.Linear(128, n_hidden[0]),\n",
        "        )\n",
        "        frequencies = torch.tensor(\n",
        "            [0] + [2 * np.pi * 1.5**i for i in range(time_embeddings - 1)]\n",
        "        )\n",
        "        self.register_buffer(\"frequencies\", frequencies)\n",
        "\n",
        "    def time_encoding(self, t: torch.Tensor) -> torch.Tensor:\n",
        "        phases = torch.concat(\n",
        "            (\n",
        "                torch.sin(t[:, None] * self.frequencies[None, :]),\n",
        "                torch.cos(t[:, None] * self.frequencies[None, :]) - 1,\n",
        "            ),\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        return self.time_embed(phases)[:, :, None, None]\n",
        "\n",
        "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
        "        # Shapes of input:\n",
        "        #    x: (batch, chan, height, width)\n",
        "        #    t: (batch,)\n",
        "\n",
        "        embed = self.blocks[0](x)\n",
        "        # ^ (batch, n_hidden[0], height, width)\n",
        "\n",
        "        # Add information about time along the diffusion process\n",
        "        #  (Providing this information by superimposing in latent space)\n",
        "        embed += self.time_encoding(t)\n",
        "        #         ^ (batch, n_hidden[0], 1, 1) - thus, broadcasting\n",
        "        #           to the entire spatial domain\n",
        "\n",
        "        for block in self.blocks[1:]:\n",
        "            embed = block(embed)\n",
        "\n",
        "        return embed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W-lme6E7yBk"
      },
      "source": [
        "Next, we define the actual diffusion model, which specifies the training\n",
        "schedule, takes an arbitrary model for estimating the\n",
        "diffusion process (such as the CNN above),\n",
        "and computes the corresponding loss (as well as generating samples)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCZe8Q651y-d"
      },
      "outputs": [],
      "source": [
        "class DDPM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        gt,\n",
        "        alphas: Tuple[float, float],\n",
        "        n_T: int,\n",
        "        criterion: nn.Module = nn.MSELoss(),\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.gt = gt\n",
        "\n",
        "        noise_schedule = ddpm_schedules(alphas[0], alphas[1], n_T)\n",
        "\n",
        "        # `register_buffer` will track these tensors for device placement, but\n",
        "        # not store them as model parameters. This is useful for constants.\n",
        "        self.register_buffer(\"alpha_t\", noise_schedule[\"alpha_t\"])\n",
        "        self.alpha_t  # Exists! Set by register_buffer\n",
        "\n",
        "        self.n_T = n_T\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        t = torch.randint(1, self.n_T, (x.shape[0],), device=x.device)\n",
        "        alpha_t = self.alpha_t[t, None, None, None]  # Get right shape for broadcasting\n",
        "        eta_t_dist = torch.distributions.Gamma(alpha_t, torch.ones_like(alpha_t))  # Create Gamma distribution\n",
        "        eta_t_sample = eta_t_dist.sample()  # Sample from the Gamma distribution\n",
        "        eta_t = eta_t_sample / alpha_t  # Scale the sampled values\n",
        "\n",
        "        z_t =  eta_t * x\n",
        "        # This is the z_t\n",
        "        # We should predict the \"error term\" from this z_t. Loss is what we return.\n",
        "\n",
        "        return self.criterion(x, self.gt(z_t, t / self.n_T))\n",
        "\n",
        "    def sample(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        alpha_n = self.alpha_t[self.n_T, None, None, None]  # Get right shape for broadcasting\n",
        "        eta_n = torch.distributions.Gamma(alpha_n, 1.0)/ alpha_n # eta_t ~ gamma(alpha_t, 1)/ alpha_t\n",
        "        z_t =  eta_n * x\n",
        "        for i in range(self.n_T, 1, -1):\n",
        "            alpha_t = self.alpha_t[i]\n",
        "            alpha_t_minus_1 = self.alpha_t[i-1]\n",
        "            tau_t_minus_1 = torch.distributions.Gamma(alpha_t_minus_1-alpha_t, 1.0)\n",
        "\n",
        "            z_t =  1/alpha_t_minus_1*(self.gt(z_t, i / self.n_T)*tau_t_minus_1+z_t*alpha_t)\n",
        "\n",
        "        return z_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe_NxtdJ7yBk"
      },
      "source": [
        "We will run this on MNIST. We perform some basic preprocessing, and set up the data loader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6jMrCRa1y-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4faf5dc-16bb-456a-9f12-d5992043bb02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 228847888.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 26705399.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 107578381.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 9477875.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0))])\n",
        "dataset = MNIST(\"./data\", train=True, download=True, transform=tf)\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=4, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5xnOBB67yBl"
      },
      "source": [
        "We create our model with a given choice of hidden layers and activation function. We also choose a learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6ApENps1y-d"
      },
      "outputs": [],
      "source": [
        "gt = CNN(in_channels=1, expected_shape=(28, 28), n_hidden=(16, 32, 32, 16), act=nn.GELU)\n",
        "# For testing: (16, 32, 32, 16)\n",
        "# For more capacity (for example): (64, 128, 256, 128, 64)\n",
        "ddpm = DDPM(gt=gt, alphas=(10, 6), n_T=5)\n",
        "optim = torch.optim.Adam(ddpm.parameters(), lr=1e-2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoHOHQ1H7yBl"
      },
      "source": [
        "We could set up a GPU if we have one, which is done below.\n",
        "\n",
        "Here, we use HuggingFace's `accelerate` library, which abstracts away all the `.to(device)` calls for us.\n",
        "This lets us focus on the model itself rather than data movement.\n",
        "It also does a few other tricks to speed up calculations.\n",
        "\n",
        "PyTorch Lightning, which we discussed during the course, is another option that also handles a lot more, but is a bit heavyweight.\n",
        "`accelerate` is a simpler option closer to raw PyTorch.\n",
        "However, if you prefer, you could choose to use Lightning for the coursework!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CeQCnSz7yBl"
      },
      "outputs": [],
      "source": [
        "accelerator = Accelerator()\n",
        "\n",
        "# We wrap our model, optimizer, and dataloaders with `accelerator.prepare`,\n",
        "# which lets HuggingFace's Accelerate handle the device placement and gradient accumulation.\n",
        "ddpm, optim, dataloader = accelerator.prepare(ddpm, optim, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuXfefY67yBm"
      },
      "source": [
        "First, let's just make sure this works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wxKbzEa1y-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b97fae-a529-44db-a3f3-1298429f7bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "for x, _ in dataloader:\n",
        "    break\n",
        "\n",
        "with torch.no_grad():\n",
        "    ddpm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td7RxtoQ7yBm"
      },
      "source": [
        "Now, let's train it. You can exit early by interrupting the kernel. Images\n",
        "are saved to the `contents` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLiE8x-c1y-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9e107d-effe-45dd-e7f0-85d394bc2f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 0.0199:  75%|███████▌  | 351/468 [07:42<02:23,  1.23s/it]"
          ]
        }
      ],
      "source": [
        "n_epoch = 2\n",
        "losses = []\n",
        "\n",
        "for i in range(n_epoch):\n",
        "    ddpm.train()\n",
        "\n",
        "    pbar = tqdm(dataloader)  # Wrap our loop with a visual progress bar\n",
        "    for x, _ in pbar:\n",
        "        optim.zero_grad()\n",
        "\n",
        "        loss = ddpm(x)\n",
        "\n",
        "        loss.backward()\n",
        "        # ^Technically should be `accelerator.backward(loss)` but not necessary for local training\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        avg_loss = np.average(losses[min(len(losses)-100, 0):])\n",
        "        pbar.set_description(f\"loss: {avg_loss:.3g}\")  # Show running average of loss in progress bar\n",
        "\n",
        "        optim.step()\n",
        "\n",
        "    ddpm.eval()\n",
        "    with torch.no_grad():\n",
        "        xh = ddpm.sample(x)  # Can get device explicitly with `accelerator.device`\n",
        "        grid = make_grid(xh, nrow=4)\n",
        "\n",
        "        # Save samples to `./contents` directory\n",
        "        save_image(grid, f\"./contents/ddpm_sample_{i:04d}.png\")\n",
        "\n",
        "        # save model\n",
        "        torch.save(ddpm.state_dict(), f\"./ddpm_mnist.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQmYj5L07yBm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}